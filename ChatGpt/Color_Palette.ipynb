{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1651d2dd-6cbb-4389-9f59-86de797f9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c410d29c-46fd-4c37-9aaf-03c95911d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e0e1e7-2c3f-471c-a4a0-c92fea465bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3735b0d8-3e18-4895-95f1-1483c932777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23ffe90-a99d-44eb-850a-398c4505174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_colors(colors):\n",
    "    display(Markdown(\" \".join(\n",
    "        f\"<span style='color:{color}'>{chr(9608) * 4}</span>\"\n",
    "        for color in colors\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a19a65-3208-4747-a6a9-1d5ee81e3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_and_render_colors_chat(msg):\n",
    "   messages = [\n",
    "       {\"role\": \"system\",\"content\":\"You are a color palette generating assistant that responds to text prompts for color palettes,Your should generate color palettes that fit the theme, mood, or instructions in the prompt.The palettes should be between 2 and 8 colors.\"},\n",
    "       {\"role\":\"user\",\"content\":\"Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\"},\n",
    "       {\"role\":\"assistant\",\"content\":'[\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]'},\n",
    "       {\"role\":\"user\",\"content\":\"Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\"},\n",
    "       {\"role\":\"assistant\",\"content\":'[\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]'},\n",
    "       {\"role\":\"user\",\"content\":f\"Convert the following verbal description of a color palette into a list of colors: {msg}\"}\n",
    "        \n",
    "   ]\n",
    "   response = openai.ChatCompletion.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=200,\n",
    "   )\n",
    "   print(response)\n",
    "\n",
    "   colors = json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "   display_colors(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44046b35-f0d4-4f54-b2ff-e6df44b8cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yEKBaVQBlyDIylOO8Pc1TSc4CIpx\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589099,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#4285F4\\\", \\\"#EA4335\\\", \\\"#FBBC05\\\", \\\"#34A853\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 182,\n",
      "    \"completion_tokens\": 22,\n",
      "    \"total_tokens\": 204\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#4285F4'>████</span> <span style='color:#EA4335'>████</span> <span style='color:#FBBC05'>████</span> <span style='color:#34A853'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"4, Google brand colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86bab035-adad-478e-855b-844e72795048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yENJLPoNqJnZClNGCPWIcGECGwfF\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589293,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#000033\\\", \\\"#000066\\\", \\\"#000099\\\", \\\"#0000CC\\\", \\\"#0000FF\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 180,\n",
      "    \"completion_tokens\": 23,\n",
      "    \"total_tokens\": 203\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#000033'>████</span> <span style='color:#000066'>████</span> <span style='color:#000099'>████</span> <span style='color:#0000CC'>████</span> <span style='color:#0000FF'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"deep night at home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2f3e467-a41e-4f06-843c-a2e2b0ed0f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yEOz01FVjn4N4Kq6qlIQg0DQbNSV\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589397,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#F4E8DA\\\", \\\"#AAA68D\\\", \\\"#6D7985\\\", \\\"#253D53\\\", \\\"#FEE715\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 180,\n",
      "    \"completion_tokens\": 29,\n",
      "    \"total_tokens\": 209\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#F4E8DA'>████</span> <span style='color:#AAA68D'>████</span> <span style='color:#6D7985'>████</span> <span style='color:#253D53'>████</span> <span style='color:#FEE715'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"good morning at factory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5099110a-406e-4d0d-96d8-7d632071f3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yEPj8nSBTfX01YiJ0WNp9qr7D3Jm\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589443,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#C0D9E5\\\", \\\"#A3C1D0\\\", \\\"#6E8BB8\\\", \\\"#4A6A9E\\\", \\\"#2C476F\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 180,\n",
      "    \"completion_tokens\": 38,\n",
      "    \"total_tokens\": 218\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#C0D9E5'>████</span> <span style='color:#A3C1D0'>████</span> <span style='color:#6E8BB8'>████</span> <span style='color:#4A6A9E'>████</span> <span style='color:#2C476F'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"blue morning at home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77250a7d-b676-43f9-9d13-ea0f1f7d4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yEQzl2hxNPqdh0S4n1Ty0h46S6Bp\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589521,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#87CEFA\\\", \\\"#F0E68C\\\", \\\"#FFE4C4\\\", \\\"#FFDAB9\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 181,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 206\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#87CEFA'>████</span> <span style='color:#F0E68C'>████</span> <span style='color:#FFE4C4'>████</span> <span style='color:#FFDAB9'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"light sky at late summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9dd6dc-27e0-4107-99ca-c9ca03fa4576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7yESQWmdcGffryUVuetLRju6c8aw2\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1694589610,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[\\\"#000033\\\", \\\"#000066\\\", \\\"#000099\\\", \\\"#0000CC\\\", \\\"#0000FF\\\", \\\"#00CCFF\\\"]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 183,\n",
      "    \"completion_tokens\": 28,\n",
      "    \"total_tokens\": 211\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:#000033'>████</span> <span style='color:#000066'>████</span> <span style='color:#000099'>████</span> <span style='color:#0000CC'>████</span> <span style='color:#0000FF'>████</span> <span style='color:#00CCFF'>████</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_and_render_colors_chat(\"night sky with bright blue neon sign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ad22b9e-c169-4554-aadd-89851300bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of laughter and glee,\n",
      "Let's talk about a funny spree.\n",
      "Tickle jokes and silly faces,\n",
      "We'll giggle until our belly embraces.\n",
      "Laughter truly sets our spirits free!\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"You are helpful assistant that create funny poems\"},\n",
    "        {\"role\":\"user\",\"content\":\"Generate me a 5 lines poems about the topic of your choosing\"}\n",
    "    ],\n",
    "    temperature= 1,\n",
    "    max_tokens = 200\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2eaee-344f-4247-9ce2-abf3d282ee6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cabaa-95d1-4b94-805d-da7ddc31a23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917349f-adf9-4321-9da1-2abd59c3f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_render_colors(msg):\\n\",\n",
    "    \"    prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"    You are a color palette generating assistant that responds to text prompts for color palettes\\n\",\n",
    "    \"    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\\n\",\n",
    "    \"    The palettes should be between 2 and 8 colors.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\\n\",\n",
    "    \"    A: [\\\"#006699\\\", \\\"#66CCCC\\\", \\\"#F0E68C\\\", \\\"#008000\\\", \\\"#F08080\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\\n\",\n",
    "    \"    A: [\\\"#EDF1D6\\\", \\\"#9DC08B\\\", \\\"#609966\\\", \\\"#40513B\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Desired Format: a JSON array of hexadecimal color codes\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Q: Convert the following verbal description of a color palette into a list of colors: {msg} \\n\",\n",
    "    \"    A:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\","
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
